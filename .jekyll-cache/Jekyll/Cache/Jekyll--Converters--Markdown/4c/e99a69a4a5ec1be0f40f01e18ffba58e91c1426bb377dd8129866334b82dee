I"X<p>This summer, I’ve had the great pleasure to work as a Research Assistant to Prof. Lin Zhong at the <a href="http://yecl.org/">Yale Efficient Computing Lab</a>. The project that I have been contributing to is related to 5G, and in particular, massive multiple-input multiple-output (MIMO). Massive MIMO involves using multiple antennas at the transmitter and reciever to improve throughput and spectral efficiency (improving speed), and it’s seen as a key technology to enable the transition to 5G mobile networks.</p>

<p>For the last few years, <a href="https://www.owlnet.rice.edu/~jianding/">Jian Ding</a> has been developing Millipede, a new software approach to real-time massive MIMO baseband processing. Massive MIMO baseband processing is a computationally intensive step in 5G that is typically done by specialized hardware such as <a href="https://en.wikipedia.org/wiki/Field-programmable_gate_array">FPGAs</a>. Because these FPGAs are installed per base station, updating the technology (say, for the upcoming transition from LTE to 5G) currently involves going to each network tower and physcially replacing hardware — an expensive and slow process.</p>

<p>The key idea of performing baseband processing in software is that rather than compute everything individually per base station, the bulk of this work can be centralized in data centers, where compute time is cheap and updating technology is as quick as changing lines of code. In this sense, Jian’s technology will enable us to move 5G base stations into the cloud!</p>

<p>To accomplish this, the software must run extremely fast — fast enough that it meets the latency standards for 5G New Radio and essentially as if everything was in real time. Every calculation and operation performed by the software must be as fast as the underlying hardware can support (in this case, general purpose processors). That is where my sub-project comes into play: implement a version of matrix-vector multiplication that is faster than the fastest public implementation out there, currently the proprietary one provided by Intel’s Math Kernel Library (MKL).</p>

<p>I’ve learned a whole lot — both nitty gritty technical and relating to the overarching process of research — and I hope to distill some of the key topics that I learned that may be interesting (hopefully helpful) to other students and researchers out there! Below are some posts and topic areas I’m planning to write about:</p>

<h2 id="planned-posts">Planned posts</h2>

<ul>
  <li>Basic Linear Algebra Subprograms (BLAS) (i.e. Intel MKL, OpenBlas, and wrappers like Armadillo, Eigen, and Numpy)</li>
  <li>Data paralellization / Single Intruction Multiple Data (SIMD)</li>
  <li>Programming with Intel Intrinsics</li>
  <li>Just-in-Time (JIT) compilation and a tutorial of the <a href="https://github.com/herumi/xbyak">Xbyak</a> JIT assembler</li>
</ul>
:ET